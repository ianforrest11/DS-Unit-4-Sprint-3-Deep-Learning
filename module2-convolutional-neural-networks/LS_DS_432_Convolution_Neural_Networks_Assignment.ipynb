{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 2*\n",
    "# Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0lfZdD_cp1t5"
   },
   "source": [
    "# Assignment\n",
    "\n",
    "Load a pretrained network from Keras, [ResNet50](https://tfhub.dev/google/imagenet/resnet_v1_50/classification/1) - a 50 layer deep network trained to recognize [1000 objects](https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt). Starting usage:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "ResNet50 = ResNet50(weights='imagenet')\n",
    "features = model.predict(x)\n",
    "\n",
    "```\n",
    "\n",
    "Next you will need to remove the last layer from the ResNet model. Here, we loop over the layers to use the sequential API. There are easier ways to add and remove layers using the Keras functional API, but doing so introduces other complexities. \n",
    "\n",
    "```python\n",
    "# Remote the Last Layer of ResNEt\n",
    "ResNet50._layers.pop(0)\n",
    "\n",
    "# Out New Model\n",
    "model = Sequential()\n",
    "\n",
    "# Add Pre-trained layers of Old Model to New Model\n",
    "for layer in ResNet50.layers:\n",
    "    model.add(layer)\n",
    "\n",
    "# Turn off additional training of ResNet Layers for speed of assignment\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add New Output Layer to Model\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "```\n",
    "\n",
    "Your assignment is to apply the transfer learning above to classify images of Mountains (`./data/mountain/*`) and images of forests (`./data/forest/*`). Treat mountains as the postive class (1) and the forest images as the negative (zero). \n",
    "\n",
    "Steps to complete assignment: \n",
    "1. Load in Image Data into numpy arrays (`X`) \n",
    "2. Create a `y` for the labels\n",
    "3. Train your model with pretrained layers from resnet\n",
    "4. Report your model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import zipfile\n",
    "import pathlib\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in mountain data from file\n",
    "\n",
    "import os\n",
    "\n",
    "mtn_img = []\n",
    "\n",
    "data_files = os.listdir('/Users/ianforrest/Desktop/coding/repos/ianforrest11/DS-Unit-4-Sprint-3-Deep-Learning/module2-convolutional-neural-networks/data/mountain')\n",
    "\n",
    "for filename in data_files:\n",
    "    if filename[-3:] == 'jpg':\n",
    "        path = f'/Users/ianforrest/Desktop/coding/repos/ianforrest11/DS-Unit-4-Sprint-3-Deep-Learning/module2-convolutional-neural-networks/data/mountain/{filename}'\n",
    "        #print(path)\n",
    "        with open(path, 'rb') as data:\n",
    "            content = data.read()\n",
    "            #print(content)\n",
    "            mtn_img.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x02\\x02\\x01\\x01\\x02\\x01\\x01\\x01\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x01\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\xff\\xdb\\x00C\\x01\\x01\\x01\\x01\\x01\\x01\\x01'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtn_img[30][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in mountain data from file\n",
    "\n",
    "import os\n",
    "\n",
    "for_img = []\n",
    "\n",
    "data_files = os.listdir('/Users/ianforrest/Desktop/coding/repos/ianforrest11/DS-Unit-4-Sprint-3-Deep-Learning/module2-convolutional-neural-networks/data/forest')\n",
    "\n",
    "for filename in data_files:\n",
    "    if filename[-3:] == 'jpg':\n",
    "        path = f'/Users/ianforrest/Desktop/coding/repos/ianforrest11/DS-Unit-4-Sprint-3-Deep-Learning/module2-convolutional-neural-networks/data/forest/{filename}'\n",
    "        #print(path)\n",
    "        with open(path, 'rb') as data:\n",
    "            content = data.read()\n",
    "            #print(content)\n",
    "            for_img.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x08\\x06\\x06\\x07\\x06\\x05\\x08\\x07\\x07\\x07\\t\\t\\x08\\n\\x0c\\x14\\r\\x0c\\x0b\\x0b\\x0c\\x19\\x12\\x13\\x0f\\x14\\x1d\\x1a\\x1f\\x1e\\x1d\\x1a\\x1c\\x1c $.\\' \",#\\x1c\\x1c(7),01444\\x1f\\'9=82<.342\\xff\\xdb\\x00C\\x01\\t\\t\\t\\x0c\\x0b\\x0c'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_img[30][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the zip files from Google Drive and unzip them into data directory\n",
    "zip_ref = zipfile.ZipFile(\"/Users/ianforrest/Desktop/coding/repos/ianforrest11/DS-Unit-4-Sprint-3-Deep-Learning/module2-convolutional-neural-networks/data/forest/forest.zip\", 'r')\n",
    "zip_ref.extractall(\"data\")\n",
    "zip_ref = zipfile.ZipFile(\"/Users/ianforrest/Desktop/coding/repos/ianforrest11/DS-Unit-4-Sprint-3-Deep-Learning/module2-convolutional-neural-networks/data/mountain/mountain.zip\", 'r')\n",
    "zip_ref.extractall(\"data\")\n",
    "zip_ref.close()\n",
    "\n",
    "data_root = pathlib.Path('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate list of image paths. There's a .db file in the image directory\n",
    "# so only glob all the .jpgs\n",
    "all_image_paths = list(data_root.glob('*/*.jpg'))\n",
    "all_image_paths = [str(path) for path in all_image_paths]\n",
    "random.shuffle(all_image_paths)\n",
    "\n",
    "image_count = len(all_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "702"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "# Resources and Stretch Goals\n",
    "\n",
    "Stretch goals\n",
    "- Enhance your code to use classes/functions and accept terms to search and classes to look for in recognizing the downloaded images (e.g. download images of parties, recognize all that contain balloons)\n",
    "- Check out [other available pretrained networks](https://tfhub.dev), try some and compare\n",
    "- Image recognition/classification is somewhat solved, but *relationships* between entities and describing an image is not - check out some of the extended resources (e.g. [Visual Genome](https://visualgenome.org/)) on the topic\n",
    "- Transfer learning - using images you source yourself, [retrain a classifier](https://www.tensorflow.org/hub/tutorials/image_retraining) with a new category\n",
    "- (Not CNN related) Use [piexif](https://pypi.org/project/piexif/) to check out the metadata of images passed in to your system - see if they're from a national park! (Note - many images lack GPS metadata, so this won't work in most cases, but still cool)\n",
    "\n",
    "Resources\n",
    "- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) - influential paper (introduced ResNet)\n",
    "- [YOLO: Real-Time Object Detection](https://pjreddie.com/darknet/yolo/) - an influential convolution based object detection system, focused on inference speed (for applications to e.g. self driving vehicles)\n",
    "- [R-CNN, Fast R-CNN, Faster R-CNN, YOLO](https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e) - comparison of object detection systems\n",
    "- [Common Objects in Context](http://cocodataset.org/) - a large-scale object detection, segmentation, and captioning dataset\n",
    "- [Visual Genome](https://visualgenome.org/) - a dataset, a knowledge base, an ongoing effort to connect structured image concepts to language"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nn]",
   "language": "python",
   "name": "conda-env-nn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
